{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./schools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "patterns = [\"children\",\"enqiures uk\", \"the\", \"learning\", \"staff\", \"good\", \"ir\", \"inspection\", \"the\", \"schools\", \"children\", \"pupils\", \"school\", \"pupil\", \"Ofsted\", \"Inspection report\", \"gov uk\", \"ofsted gov\", \"early year\", \"uk government\", \"www.ofsted.gov.uk\", \"www.gov.uk/ofsted\", \"Early Year\", \"ofsted\", \"gov\", \"Inspection Report\"] # filter out common words\n",
    "closed_school_names = []\n",
    "closed_reports = []\n",
    "closed = []\n",
    "closed_root = root+'/closed/'\n",
    "for path, subdirs, files in os.walk(closed_root):\n",
    "    for s in subdirs:\n",
    "        f = os.path.join(path,s)\n",
    "        for p2, s2, f2 in os.walk(f):\n",
    "            for doc in f2:\n",
    "                txt = open(os.path.join(p2,doc), 'r')\n",
    "                content = txt.read()\n",
    "                if re.search('Childminder Report',content):\n",
    "                    continue\n",
    "                if re.search('Childminder',content):\n",
    "                    continue\n",
    "                content = content.replace('\\n',' ')\n",
    "                for pattern in patterns:\n",
    "                    content = content.replace(pattern,'')\n",
    "                if content == '':\n",
    "                    continue\n",
    "                closed_reports.append(doc.replace('.txt',''))\n",
    "                closed_school_names.append(s)\n",
    "                closed.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\"children\",\"enqiures uk\", \"the\", \"learning\", \"staff\", \"good\", \"ir\", \"inspection\", \"the\", \"schools\", \"children\", \"pupils\", \"school\", \"pupil\", \"Ofsted\", \"Inspection report\", \"gov uk\", \"ofsted gov\", \"early year\", \"uk government\", \"www.ofsted.gov.uk\", \"www.gov.uk/ofsted\", \"Early Year\", \"ofsted\", \"gov\", \"Inspection Report\"] # filter out common words\n",
    "opened = []\n",
    "open_school_names = []\n",
    "open_reports = []\n",
    "open_root = root+'/open/'\n",
    "for path, subdirs, files in os.walk(open_root):\n",
    "    for s in subdirs:\n",
    "        f = os.path.join(path,s)\n",
    "    for p2, s2, f2 in os.walk(f):\n",
    "        for doc in f2:\n",
    "            txt = open(os.path.join(p2,doc),'r')\n",
    "            content = txt.read()\n",
    "            if re.search('Childminder Report',content):\n",
    "                continue\n",
    "            if re.search('Childminder',content):\n",
    "                continue\n",
    "            content = content.replace('\\n','')\n",
    "            for pattern in patterns:\n",
    "                content = content.replace(pattern,' ')\n",
    "            if content == '':\n",
    "                continue\n",
    "            open_reports.append(doc.replace('.txt',''))\n",
    "            open_school_names.append(s)\n",
    "            opened.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_closed = pd.DataFrame()\n",
    "closed_labels = [\"closed\" for school in closed]\n",
    "df_closed[\"school\"] = closed_school_names\n",
    "df_closed[\"text\"] = closed\n",
    "df_closed[\"label\"] = closed_labels\n",
    "df_closed[\"file\"] = closed_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tweeddale Primary School</td>\n",
       "      <td>Existing a...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2593199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tweeddale Primary School</td>\n",
       "      <td>Scho...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50055540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loganberries Childcare And Tutoring Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2566925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dovedale Before and After School Club Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2669737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URN: 302140 Closed</td>\n",
       "      <td>for s provision  Uni...</td>\n",
       "      <td>closed</td>\n",
       "      <td>1415927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         school  \\\n",
       "0                      Tweeddale Primary School   \n",
       "1                      Tweeddale Primary School   \n",
       "2    Loganberries Childcare And Tutoring Closed   \n",
       "3  Dovedale Before and After School Club Closed   \n",
       "4                            URN: 302140 Closed   \n",
       "\n",
       "                                                text   label      file  \n",
       "0                                      Existing a...  closed   2593199  \n",
       "1                                            Scho...  closed  50055540  \n",
       "2                                                ...  closed   2566925  \n",
       "3                                                ...  closed   2669737  \n",
       "4                            for s provision  Uni...  closed   1415927  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_closed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out schools that were marked as closed due to academy conversion\n",
    "import numpy as np\n",
    "df_closed = df_closed.replace(np.nan, '', regex=True)\n",
    "df_closed = df_closed[~df_closed.text.apply(lambda x: bool(re.search(\"academy converters\",x,re.IGNORECASE)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open = pd.DataFrame()\n",
    "open_labels = [\"open\" for school in opened]\n",
    "df_open[\"school\"] = open_school_names\n",
    "df_open[\"text\"] = opened\n",
    "df_open[\"label\"] = open_labels\n",
    "df_open[\"file\"] = open_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URN: EY557468</td>\n",
       "      <td>Piccadilly GateStore StreetManchesterM1 2WDTe...</td>\n",
       "      <td>open</td>\n",
       "      <td>50052428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URN: EY557468</td>\n",
       "      <td>Piccadilly GateStore StreetManchesterM1 2WDTe...</td>\n",
       "      <td>open</td>\n",
       "      <td>50052428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URN: EY557468</td>\n",
       "      <td>Piccadilly GateStore StreetManchesterM1 2WDTe...</td>\n",
       "      <td>open</td>\n",
       "      <td>50052428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URN: EY557468</td>\n",
       "      <td>Piccadilly GateStore StreetManchesterM1 2WDTe...</td>\n",
       "      <td>open</td>\n",
       "      <td>50052428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URN: EY557468</td>\n",
       "      <td>Piccadilly GateStore StreetManchesterM1 2WDTe...</td>\n",
       "      <td>open</td>\n",
       "      <td>50052428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          school                                               text label  \\\n",
       "0  URN: EY557468   Piccadilly GateStore StreetManchesterM1 2WDTe...  open   \n",
       "1  URN: EY557468   Piccadilly GateStore StreetManchesterM1 2WDTe...  open   \n",
       "2  URN: EY557468   Piccadilly GateStore StreetManchesterM1 2WDTe...  open   \n",
       "3  URN: EY557468   Piccadilly GateStore StreetManchesterM1 2WDTe...  open   \n",
       "4  URN: EY557468   Piccadilly GateStore StreetManchesterM1 2WDTe...  open   \n",
       "\n",
       "       file  \n",
       "0  50052428  \n",
       "1  50052428  \n",
       "2  50052428  \n",
       "3  50052428  \n",
       "4  50052428  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_open.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['closed', 'open'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_closed.append(df_open, ignore_index=True)\n",
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tweeddale Primary School</td>\n",
       "      <td>Scho...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50055540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loganberries Childcare And Tutoring Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2566925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dovedale Before and After School Club Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2669737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URN: 302140 Closed</td>\n",
       "      <td>for s provision  Uni...</td>\n",
       "      <td>closed</td>\n",
       "      <td>1415927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pepe &amp; Friends</td>\n",
       "      <td>Pepe &amp; Friends...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50070828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         school  \\\n",
       "0                      Tweeddale Primary School   \n",
       "1    Loganberries Childcare And Tutoring Closed   \n",
       "2  Dovedale Before and After School Club Closed   \n",
       "3                            URN: 302140 Closed   \n",
       "4                                Pepe & Friends   \n",
       "\n",
       "                                                text   label      file  \n",
       "0                                            Scho...  closed  50055540  \n",
       "1                                                ...  closed   2566925  \n",
       "2                                                ...  closed   2669737  \n",
       "3                            for s provision  Uni...  closed   1415927  \n",
       "4                                  Pepe & Friends...  closed  50070828  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of closed school documents: 107758\n",
      "Total number of open school documents: 280864\n"
     ]
    }
   ],
   "source": [
    "print (\"Total number of closed school documents: {}\".format(len(closed)))\n",
    "print (\"Total number of open school documents: {}\".format(len(opened)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed schools after filtering for academy converters: 105451\n",
      "Open schools: 280864\n"
     ]
    }
   ],
   "source": [
    "print (\"Closed schools after filtering for academy converters: {}\".format(len(df_closed))) # 530 after filtering out academy converter\n",
    "print (\"Open schools: {}\".format(len(df_open)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dates from other CSVs\n",
    "closed_dates_df = pd.read_csv('closed_school_dates.csv')\n",
    "open_dates_df = pd.read_csv('open_school_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>report</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>2074707</td>\n",
       "      <td>11 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>964165</td>\n",
       "      <td>28 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>902265</td>\n",
       "      <td>29 September 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>794867</td>\n",
       "      <td>25 November 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brook House Farm Closed</td>\n",
       "      <td>2457113</td>\n",
       "      <td>21 January 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             school   report               date\n",
       "0  Chesterton Primary School Closed  2074707  11 September 2012\n",
       "1  Chesterton Primary School Closed   964165  28 September 2012\n",
       "2  Chesterton Primary School Closed   902265  29 September 2009\n",
       "3  Chesterton Primary School Closed   794867   25 November 2009\n",
       "4           Brook House Farm Closed  2457113    21 January 2015"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>report</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URN: EY427182</td>\n",
       "      <td>2523582</td>\n",
       "      <td>02 November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URN: EY427182</td>\n",
       "      <td>2024971</td>\n",
       "      <td>26 November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URN: EY427207</td>\n",
       "      <td>2620447</td>\n",
       "      <td>18 November 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URN: EY427207</td>\n",
       "      <td>2204223</td>\n",
       "      <td>08 December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URN: EY427217</td>\n",
       "      <td>2527377</td>\n",
       "      <td>17 November 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          school   report              date\n",
       "0  URN: EY427182  2523582  02 November 2015\n",
       "1  URN: EY427182  2024971  26 November 2015\n",
       "2  URN: EY427207  2620447  18 November 2016\n",
       "3  URN: EY427207  2204223  08 December 2016\n",
       "4  URN: EY427217  2527377  17 November 2015"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of closed documents with dates: 77773\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of closed documents with dates: {}\".format(len(closed_dates_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of open documents with dates: 211965\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of open documents with dates: {}\".format(len(open_dates_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = closed_dates_df.append(open_dates_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>report</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>2074707</td>\n",
       "      <td>11 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>964165</td>\n",
       "      <td>28 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>902265</td>\n",
       "      <td>29 September 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chesterton Primary School Closed</td>\n",
       "      <td>794867</td>\n",
       "      <td>25 November 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brook House Farm Closed</td>\n",
       "      <td>2457113</td>\n",
       "      <td>21 January 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             school   report               date\n",
       "0  Chesterton Primary School Closed  2074707  11 September 2012\n",
       "1  Chesterton Primary School Closed   964165  28 September 2012\n",
       "2  Chesterton Primary School Closed   902265  29 September 2009\n",
       "3  Chesterton Primary School Closed   794867   25 November 2009\n",
       "4           Brook House Farm Closed  2457113    21 January 2015"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2074707</td>\n",
       "      <td>11 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964165</td>\n",
       "      <td>28 September 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902265</td>\n",
       "      <td>29 September 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>794867</td>\n",
       "      <td>25 November 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2457113</td>\n",
       "      <td>21 January 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file               date\n",
       "0  2074707  11 September 2012\n",
       "1   964165  28 September 2012\n",
       "2   902265  29 September 2009\n",
       "3   794867   25 November 2009\n",
       "4  2457113    21 January 2015"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dates.drop('school',axis=1)\n",
    "dates.columns = ['file','date'] # Rename column so they match\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tweeddale Primary School</td>\n",
       "      <td>Scho...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50055540</td>\n",
       "      <td>15 January 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loganberries Childcare And Tutoring Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2566925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dovedale Before and After School Club Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2669737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URN: 302140 Closed</td>\n",
       "      <td>for s provision  Uni...</td>\n",
       "      <td>closed</td>\n",
       "      <td>1415927</td>\n",
       "      <td>25 November 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pepe &amp; Friends</td>\n",
       "      <td>Pepe &amp; Friends...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50070828</td>\n",
       "      <td>21 May 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         school  \\\n",
       "0                      Tweeddale Primary School   \n",
       "1    Loganberries Childcare And Tutoring Closed   \n",
       "2  Dovedale Before and After School Club Closed   \n",
       "3                            URN: 302140 Closed   \n",
       "4                                Pepe & Friends   \n",
       "\n",
       "                                                text   label      file  \\\n",
       "0                                            Scho...  closed  50055540   \n",
       "1                                                ...  closed   2566925   \n",
       "2                                                ...  closed   2669737   \n",
       "3                            for s provision  Uni...  closed   1415927   \n",
       "4                                  Pepe & Friends...  closed  50070828   \n",
       "\n",
       "               date  \n",
       "0   15 January 2019  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3  25 November 2014  \n",
       "4       21 May 2019  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file'] = df['file'].astype(int)\n",
    "df_merge = pd.merge(df, dates, on='file', how='outer')\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that only have dates\n",
    "df_merge = df_merge[pd.notnull(df_merge['school'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386370"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['text'] = df_merge['text'].str.replace(\"[^a-zA-Z]\", \" \") # Clean up non-alphabetical symbols\n",
    "df_merge = df_merge.replace(np.nan, ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "mask = np.random.rand(len(df_merge)) < 0.8\n",
    "train = df_merge.loc[mask]\n",
    "test = df_merge.loc[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tweeddale Primary School</td>\n",
       "      <td>Scho...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50055540</td>\n",
       "      <td>15 January 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URN: 302140 Closed</td>\n",
       "      <td>for s provision  Uni...</td>\n",
       "      <td>closed</td>\n",
       "      <td>1415927</td>\n",
       "      <td>25 November 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pepe &amp; Friends</td>\n",
       "      <td>Pepe   Friends...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50070828</td>\n",
       "      <td>21 May 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pepe &amp; Friends</td>\n",
       "      <td>Pepe   Friends...</td>\n",
       "      <td>closed</td>\n",
       "      <td>50040089</td>\n",
       "      <td>20 March 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pepe &amp; Friends</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2779003</td>\n",
       "      <td>11 October 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     school  \\\n",
       "0  Tweeddale Primary School   \n",
       "3        URN: 302140 Closed   \n",
       "4            Pepe & Friends   \n",
       "5            Pepe & Friends   \n",
       "6            Pepe & Friends   \n",
       "\n",
       "                                                text   label      file  \\\n",
       "0                                            Scho...  closed  50055540   \n",
       "3                            for s provision  Uni...  closed   1415927   \n",
       "4                                  Pepe   Friends...  closed  50070828   \n",
       "5                                  Pepe   Friends...  closed  50040089   \n",
       "6                                                ...  closed   2779003   \n",
       "\n",
       "               date  \n",
       "0   15 January 2019  \n",
       "3  25 November 2014  \n",
       "4       21 May 2019  \n",
       "5     20 March 2019  \n",
       "6   11 October 2018  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loganberries Childcare And Tutoring Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2566925</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dovedale Before and After School Club Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2669737</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cottonstones Pre-School Playgroup Closed</td>\n",
       "      <td>Unt...</td>\n",
       "      <td>closed</td>\n",
       "      <td>1095087</td>\n",
       "      <td>07 July 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>St Mary and St John Junior and Infant School C...</td>\n",
       "      <td>Scho...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2686395</td>\n",
       "      <td>09 October 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>St Mary and St John Junior and Infant School C...</td>\n",
       "      <td>Unt...</td>\n",
       "      <td>closed</td>\n",
       "      <td>879089</td>\n",
       "      <td>07 April 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               school  \\\n",
       "1          Loganberries Childcare And Tutoring Closed   \n",
       "2        Dovedale Before and After School Club Closed   \n",
       "9            Cottonstones Pre-School Playgroup Closed   \n",
       "11  St Mary and St John Junior and Infant School C...   \n",
       "13  St Mary and St John Junior and Infant School C...   \n",
       "\n",
       "                                                 text   label     file  \\\n",
       "1                                                 ...  closed  2566925   \n",
       "2                                                 ...  closed  2669737   \n",
       "9                                              Unt...  closed  1095087   \n",
       "11                                            Scho...  closed  2686395   \n",
       "13                                             Unt...  closed   879089   \n",
       "\n",
       "               date  \n",
       "1                    \n",
       "2                    \n",
       "9      07 July 2010  \n",
       "11  09 October 2018  \n",
       "13    07 April 2011  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.sample(int(len(train)*0.01))\n",
    "train_df.to_csv('train_sample.csv')\n",
    "test_df = test.sample(int(len(test)*0.01))\n",
    "test_df.to_csv('test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv')\n",
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_sample.csv')\n",
    "test = pd.read_csv('../data/test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing open schools in training: 200405\n",
      "printing closed schools in training: 84564\n"
     ]
    }
   ],
   "source": [
    "print(\"printing open schools in training: {}\".format(len(train[train['label'] == 'open'])))\n",
    "print(\"printing closed schools in training: {}\".format(len(train[train['label'] == 'closed'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing open schools in training: 49843\n",
      "printing closed schools in training: 20942\n"
     ]
    }
   ],
   "source": [
    "print(\"printing open schools in training: {}\".format(len(test[test['label'] == 'open'])))\n",
    "print(\"printing closed schools in training: {}\".format(len(test[test['label'] == 'closed'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns = df_merge.columns[df_merge.isnull().any()] # Check for null values\n",
    "df_merge[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom ItemBase subclass to handle a combination of text and tabular data\n",
    "Original source: https://github.com/anhquan0412/fastai-tabular-text-demo/blob/master/fastai_tab_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai.text.data import _join_texts\n",
    "from fastai.text import *\n",
    "\n",
    "class TabularText(TabularLine):\n",
    "    \"Item's that include both tabular data(`conts` and `cats`) and textual data (numericalized `ids`)\"\n",
    "    \n",
    "    def __init__(self, cats, conts, cat_classes, col_names, txt_ids, txt_cols, txt_string):\n",
    "        # tabular\n",
    "        super().__init__(cats, conts, cat_classes, col_names)\n",
    "\n",
    "        # add the text bits\n",
    "        self.text_ids = txt_ids\n",
    "        self.text_cols = txt_cols\n",
    "        self.text = txt_string\n",
    "        \n",
    "        # append numericalted text data to your input (represents your X values that are fed into your model)\n",
    "        # self.data = [tensor(cats), tensor(conts), tensor(txt_ids)]\n",
    "        self.data += [ np.array(txt_ids, dtype=np.int64) ]\n",
    "        self.obj = self.data\n",
    "        \n",
    "    def __str__(self):\n",
    "        res = super().__str__() + f'Text: {self.text}'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularTextProcessor(TabularProcessor):\n",
    "    # The processors are called at the end of the labelling to apply some kind of function on your items. \n",
    "    # The default processor of the inputs can be overriden by passing a processor in the kwargs when creating the ItemList, \n",
    "    # the default processor of the targets can be overriden by passing a processor in the kwargs of the labelling function.\n",
    "    def __init__(self, ds:ItemList=None, procs=None, \n",
    "                 #tokenize processor args\n",
    "                 tokenizer:Tokenizer=None, chunksize:int=10000, mark_fields:bool=False,\n",
    "                 include_bos:bool=True, include_eos:bool=False\n",
    "                 , #include_bos, include_eos for def proces\n",
    "                 \n",
    "                 # numericalize processor args\n",
    "                 vocab:Vocab=None, max_vocab:int=60000, min_freq:int=2):\n",
    "        super().__init__(ds, procs)\n",
    "        \n",
    "        # Source: fastai.text.data.TokenizeProcessor\n",
    "        self.tokenizer,self.chunksize,self.mark_fields = ifnone(tokenizer, Tokenizer()),chunksize,mark_fields\n",
    "        self.include_bos, self.include_eos = include_bos, include_eos\n",
    "        \n",
    "        # Source: fastai.text.data.NumericalizeProcessor\n",
    "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
    "        self.vocab, self.max_vocab, self.min_freq = vocab, max_vocab, min_freq\n",
    "\n",
    "        # add text_cols property\n",
    "        self.text_cols = ds.text_cols\n",
    "        \n",
    "    # process a single item in a dataset\n",
    "    # NOTE: THIS IS METHOD HAS NOT BEEN TESTED AT THIS POINT (WILL COVER IN A FUTURE ARTICLE)\n",
    "    def process_one(self, item):\n",
    "        # process tabular data (copied form tabular.data)\n",
    "        df = pd.DataFrame([item, item])\n",
    "        for proc in self.procs: proc(df, test=True)\n",
    "            \n",
    "        if len(self.cat_names) != 0:\n",
    "            codes = np.stack([c.cat.codes.values for n,c in df[self.cat_names].items()], 1).astype(np.int64) + 1\n",
    "        else: \n",
    "            codes = [[]]\n",
    "            \n",
    "        if len(self.cont_names) != 0:\n",
    "            conts = np.stack([c.astype('float32').values for n,c in df[self.cont_names].items()], 1)\n",
    "        else: \n",
    "            conts = [[]]\n",
    "            \n",
    "        classes = None\n",
    "        col_names = list(df[self.cat_names].columns.values) + list(df[self.cont_names].columns.values)\n",
    "        \n",
    "        # process textual data\n",
    "        if len(self.text_cols) != 0:\n",
    "            txt = text.data._join_texts(df[self.text_cols].values, (len(self.text_cols) > 1))\n",
    "            txt_toks = self.tokenizer._process_all_1(txt)[0]\n",
    "            text_ids = np.array(self.vocab.numericalize(txt_toks), dtype=np.int64)\n",
    "        else:\n",
    "            txt_toks, text_ids = None, [[]]\n",
    "            \n",
    "        # return ItemBase\n",
    "        return TabularText(codes[0], conts[0], classes, col_names, text_ids, self.text_cols, txt_toks)\n",
    "    \n",
    "    # processes the entire dataset\n",
    "    def process(self, ds):\n",
    "        '''\n",
    "        ds is itembase\n",
    "        '''\n",
    "        # process tabular data and then set \"preprocessed=False\" since we still have text data possibly\n",
    "        super().process(ds)\n",
    "        ds.preprocessed = False\n",
    "        \n",
    "        # process text data from column(s) containing text\n",
    "        if len(ds.text_cols) != 0:\n",
    "            texts = text.data._join_texts(ds.inner_df[ds.text_cols].values, self.mark_fields, self.include_bos, self.include_eos)\n",
    "\n",
    "            # tokenize (set = .text)\n",
    "            tokens = []\n",
    "            for i in progress_bar(range(0, len(ds), self.chunksize), leave=False):\n",
    "                tokens += self.tokenizer.process_all(texts[i:i+self.chunksize])\n",
    "            ds.text = tokens\n",
    "            \n",
    "            # numericalize \n",
    "            # set/build vocab\n",
    "            # TODO: not sure about this\n",
    "            if self.vocab is None: self.vocab = Vocab.create(ds.text, self.max_vocab, self.min_freq)\n",
    "            ds.vocab = self.vocab\n",
    "            ds.text_ids = [ np.array(self.vocab.numericalize(toks), dtype=np.int64) for toks in ds.text ]\n",
    "        else:\n",
    "            ds.text, ds.vocab, ds.text_ids = None, None, []\n",
    "            \n",
    "        ds.preprocessed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility function to pad the text to be the same size\n",
    "According to the tutorial, you need to add padding to ensure a square matrix per batch before integrating text bits with tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_tabular_pad_collate(samples:BatchSamples, \n",
    "                              pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding.\"\n",
    "    # we need to add padding to the column with the text ids in order to ensure \n",
    "    # a square matrix per batch before integrating the text bits with the tabular.\n",
    "    \n",
    "    # Source: fastai.text.data.pad_collate\n",
    "    samples = to_data(samples)\n",
    "    max_len = max([len(s[0][-1]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "#     if backwards: pad_first = not pad_first #TODO: add this\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res[i,-len(s[0][-1]):] = LongTensor(s[0][-1])\n",
    "        else:         \n",
    "            res[i,:len(s[0][-1]):] = LongTensor(s[0][-1])\n",
    "            \n",
    "        # replace the text_ids array (the last thing in the inputs) with the padded tensor matrix\n",
    "        samples[i][0][-1] = res[i]\n",
    "    \n",
    "\n",
    "    # for the inputs, return a list containing 3 elements: a list of cats, a list of conts, and a list of text_ids\n",
    "    # also include tensor list of classes\n",
    "    return [torch.stack(x) for x in zip(*[s[0] for s in samples])],tensor(np.array([s[1] for s in samples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularTextDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs=32, \n",
    "               pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> DataBunch:\n",
    "        # each \"ds\" is of type LabelList(Dataset)\n",
    "        \n",
    "        # Source: fastai.text.data.TextClasDataBunch\n",
    "        # only thing we're doing here is setting the collate_fn = to our new \"pad_collate\" method above\n",
    "        # TODO: not sure how to include SortishSampler, comparing to TextClasDataBunch\n",
    "        collate_fn = partial(mixed_tabular_pad_collate, pad_idx=pad_idx, pad_first=pad_first)\n",
    "        \n",
    "        return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom ItemList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularTextList(TabularList):\n",
    "    \"A custom `ItemList` that merges tabular data along with textual data\"\n",
    "    \n",
    "    _item_cls = TabularText\n",
    "    _processor = TabularTextProcessor\n",
    "    _bunch = TabularTextDataBunch\n",
    "    \n",
    "    def __init__(self, items:Iterator, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
    "                 text_cols=None, vocab:Vocab=None, pad_idx:int=1, \n",
    "                 procs=None, **kwargs) -> 'MixedTabularList':\n",
    "        super().__init__(items, cat_names, cont_names, procs, **kwargs)\n",
    "        \n",
    "        self.cols = [] if cat_names == None else cat_names.copy()\n",
    "        if cont_names: self.cols += cont_names.copy()\n",
    "        if text_cols: self.cols += text_cols.copy()\n",
    "        \n",
    "        # from TextList\n",
    "        self.text_cols, self.vocab, self.pad_idx = text_cols, vocab, pad_idx\n",
    "        \n",
    "        # add any ItemList state into \"copy_new\" that needs to be copied each time \"new()\" is called; \n",
    "        # your ItemList acts as a prototype for training, validation, and/or test ItemList instances that\n",
    "        # are created via ItemList.new()\n",
    "        self.copy_new += ['text_cols', 'vocab', 'pad_idx']\n",
    "        \n",
    "        self.preprocessed = False\n",
    "        \n",
    "    # defines how to construct an ItemBase from the data in the ItemList.items array\n",
    "    def get(self, i):\n",
    "        if not self.preprocessed: \n",
    "            return self.inner_df.iloc[i][self.cols] if hasattr(self, 'inner_df') else self.items[i]\n",
    "        \n",
    "        codes = [] if self.codes is None else self.codes[i]\n",
    "        conts = [] if self.conts is None else self.conts[i]\n",
    "        \n",
    "        #from TextList\n",
    "        text_ids = [] if self.text_ids is None else self.text_ids[i]\n",
    "        text_string = None if self.text_ids is None else self.vocab.textify(self.text_ids[i])\n",
    "        \n",
    "        return self._item_cls(codes, conts, self.classes, self.col_names, text_ids, self.text_cols, text_string)\n",
    "    \n",
    "    # this is the method that is called in data.show_batch(), learn.predict() or learn.show_results() \n",
    "    # to transform a pytorch tensor back in an ItemBase. \n",
    "    # in a way, it does the opposite of calling ItemBase.data. It should take a tensor t and return \n",
    "    # the same kind of thing as the get method.\n",
    "    def reconstruct(self, t:Tensor):\n",
    "        idx_min = (t[2] != self.pad_idx).nonzero().min()\n",
    "        idx_max = (t[2] != self.pad_idx).nonzero().max()\n",
    "        return self._item_cls(t[0], t[1], self.classes, self.col_names, \n",
    "                              t[2][idx_min:idx_max+1], self.text_cols, self.vocab.textify(t[2][idx_min:idx_max]+1))\n",
    "        \n",
    "#         return self._item_cls(t[0], t[1], self.classes, self.col_names, \n",
    "#                               t[2], self.text_cols, self.vocab.textify(t[2]))       \n",
    "        \n",
    "    # tells fastai how to display a custom ItemBase when data.show_batch() is called\n",
    "    def show_xys(self, xs, ys) -> None:\n",
    "        \"Show the `xs` (inputs) and `ys` (targets).\"\n",
    "        from IPython.display import display, HTML\n",
    "        \n",
    "        # show tabular\n",
    "        display(HTML('TABULAR:<br>'))\n",
    "        super().show_xys(xs, ys)\n",
    "        \n",
    "        # show text        \n",
    "        display(HTML('TEXT:<br>'))        \n",
    "        names = ['text', 'target']\n",
    "        items = []\n",
    "        max_len = 70\n",
    "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
    "            txt_x = x.text\n",
    "            items.append([txt_x, y])\n",
    "#             res = []\n",
    "#             res.append(' '.join([ f'{tok}({self.vocab.stoi[tok]})' \n",
    "#                               for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ]))\n",
    "                \n",
    "#             res.append(str(y))\n",
    "#             items.append(res)\n",
    "\n",
    "        items = np.array(items)\n",
    "        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)})\n",
    "        with pd.option_context('display.max_colwidth', -1):\n",
    "            display(HTML(df.to_html(index=False)))\n",
    "        \n",
    "    # tells fastai how to display a custom ItemBase when learn.show_results() is called\n",
    "    def show_xyzs(self, xs, ys, zs):\n",
    "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions).\"\n",
    "        from IPython.display import display, HTML\n",
    "        \n",
    "        # show tabular\n",
    "        display(HTML('TABULAR:<br>'))\n",
    "        super().show_xyzs(xs, ys, zs)\n",
    "        \n",
    "        # show text        \n",
    "        display(HTML('TEXT:<br>'))        \n",
    "        names = ['text', 'target','pred']\n",
    "        items = []\n",
    "        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n",
    "            res = []\n",
    "            res.append(' '.join([ f'{tok}({self.vocab.stoi[tok]})' \n",
    "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ]))\n",
    "                \n",
    "            res += [str(y),str(z)]\n",
    "            items.append(res)\n",
    "            \n",
    "        items = np.array(items)\n",
    "        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)})\n",
    "        with pd.option_context('display.max_colwidth', -1):\n",
    "            display(HTML(df.to_html(index=False)))\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_df(cls, df:DataFrame, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
    "                text_cols=None, vocab=None, procs=None, **kwargs) -> 'ItemList':\n",
    "        \n",
    "        return cls(items=range(len(df)), cat_names=cat_names, cont_names=cont_names, \n",
    "                   text_cols=text_cols, vocab=vocab, procs=procs, inner_df=df.copy(), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a language model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# partial_train = train.sample(int(len(train)/4)) \n",
    "# print(len(partial_train))\n",
    "# partial_test = test.sample(int(len(test)/4))\n",
    "# print(len(partial_test))\n",
    "# data_lm = (TextLMDataBunch.from_df(path='./',train_df=partial_train, \n",
    "#             valid_df=partial_test, text_cols='text', label_cols='label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm.save('data_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data('./', 'data_lm.pkl', bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2024' class='' max='96452', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.10% [2024/96452 22:59<17:52:43 3.7009]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bs32-awdlstm-stage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bs32-awdlstm-stage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bs32-awdlstm-stage2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bs32-awdlstm-stage2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, 1e-4, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bs60-awdlstm-stage2-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('bs60-awdlstm-enc-stage2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"This school is\"\n",
    "N_WORDS = 40\n",
    "\n",
    "for temp in [0.1,0.5,1,1.5,2,2.5]: # prediction: from conservative to 'why not' \n",
    "    print(learn.predict(TEXT, N_WORDS, temperature=temp))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use custom items with the Data Block API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['date','school']\n",
    "cont_cols = []\n",
    "txt_cols = ['text']\n",
    "dep_var = ['label']\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_train = train.sample(int(len(train)/100)) \n",
    "print(len(partial_train))\n",
    "partial_test = test.sample(int(len(test)/100))\n",
    "print(len(partial_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemList = (TabularTextList.from_df(train, cat_cols, \n",
    "            cont_cols, txt_cols, vocab=data_lm.vocab, \n",
    "            procs=procs, path='./')\n",
    "            .split_by_rand_pct(valid_pct=0.2)\n",
    "            .label_from_df(cols=dep_var)\n",
    "            .add_test(TabularTextList.from_df(test, cat_cols, \n",
    "                    cont_cols, txt_cols, path='./')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CATS:\\n{itemList.cat_names}')\n",
    "print(f'CONTS:\\n{itemList.cont_names}')\n",
    "print(f'TEXT COLS:\\n{itemList.text_cols}')\n",
    "print(f'PROCS:\\n{itemList.procs}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make databunch\n",
    "collate_fn = partial(mixed_tabular_pad_collate, pad_idx=1, pad_first=True)\n",
    "data = itemList.databunch(bs=32, collate_fn=collate_fn, no_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom learner and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLinearTabularTextClassifier(nn.Module):\n",
    "    \"Create a linear classifier with pooling.\"\n",
    "\n",
    "    def __init__(self, rnn_lin_layers:Collection[int], ps_lin_ftrs:Collection[float],\n",
    "                 # tabular params inputs\n",
    "                 emb_szs,n_cont,n_class,layers,ps,emb_drop,y_range,use_bn,bn_final):\n",
    "        # rnn_lin_layers: e.g [1200, 50, 1]\n",
    "        # ps_lin_ftrs: e.g [0.4 (from output_p layer1200), 0.1 for layer50]\n",
    "        \n",
    "        super().__init__()\n",
    "        # text layers. Source: fastai.text.learner.PoolingLinearClassifier\n",
    "        mod_layers = []\n",
    "        activs = [nn.ReLU(inplace=True)] * (len(rnn_lin_layers) - 2) + [None]\n",
    "        for n_in,n_out,p,actn in zip(rnn_lin_layers[:-1],rnn_lin_layers[1:], ps_lin_ftrs, activs):\n",
    "            mod_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn)\n",
    "        mod_layers = mod_layers[:-1] # exclude the last linear output\n",
    "        self.rnn_lin_layers = nn.Sequential(*mod_layers) \n",
    "        \n",
    "    \n",
    "        #tabular layers. Source: fastai.tabular.models.TabularModel\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        ps = listify(ps, layers)\n",
    "                \n",
    "        # embedding stuff\n",
    "        self.embeds = nn.ModuleList([embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(emb_drop) # drop for embedding\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) # bn for continuous features\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds) # total length of cat embeddings\n",
    "        \n",
    "               \n",
    "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
    "        sizes = self.get_sizes(layers, rnn_lin_layers[-2],n_class) # e.g [343, 222, 111, 1] ->convert to [343+ 50, 222, 111, 1]        \n",
    "        actns = [nn.ReLU(inplace=True)] * (len(sizes)-2) + [None] # [ReLU(inplace), ReLU(inplace), None]\n",
    "        \n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def get_sizes(self, layers, rnn_lin_layer, out_sz):\n",
    "        # concatenate cat,conts of tabular and rnn lin layer \n",
    "        return [self.n_emb + self.n_cont + rnn_lin_layer] + layers + [out_sz]\n",
    "    \n",
    "    \n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor,Tensor,Tensor]):\n",
    "        x_cat,x_cont,raw_outputs,outputs,mask = input\n",
    "#     def forward(self, x_cat,x_cont,raw_outputs,outputs,mask):\n",
    "\n",
    "        # text\n",
    "        output = outputs[-1]\n",
    "        avg_pool = output.masked_fill(mask[:,:,None], 0).mean(dim=1)\n",
    "        avg_pool *= output.size(1) / (output.size(1)-mask.float().sum(dim=1))[:,None]\n",
    "        max_pool = output.masked_fill(mask[:,:,None], -float('inf')).max(dim=1)[0]\n",
    "        x_text = torch.cat([output[:,-1], max_pool, avg_pool], 1) #(bs,1200) for AWD LSTM\n",
    "        x_text = self.rnn_lin_layers(x_text) # (bs,50)\n",
    "        \n",
    "        # tabular\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "            \n",
    "        x = torch.cat([x_text,x],1)\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None:\n",
    "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
    "        return x,raw_outputs,outputs # TODO: why do we need raw_outputs and outputs?\n",
    "\n",
    "class MultiBatchMixEncoder(MultiBatchEncoder):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt:int, max_len:int, module:nn.Module, pad_idx:int=1):\n",
    "        super().__init__(bptt,max_len,module,pad_idx)\n",
    "\n",
    "\n",
    "#     def forward(self,x_cat:Tensor,x_cont:Tensor,x_text:Tensor):\n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor]):\n",
    "        # Source: fastai.text.learner.MultiBatchEncoder.forward func\n",
    "        x_cat,x_cont,x_text = input\n",
    "        bs,sl = x_text.size()\n",
    "        self.reset()\n",
    "        raw_outputs,outputs,masks = [],[],[]\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            r, o = self.module(x_text[:,i: min(i+self.bptt, sl)]) # call AWS LSTM model\n",
    "            if i>(sl-self.max_len):\n",
    "                masks.append(x_text[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "                raw_outputs.append(r)\n",
    "                outputs.append(o)\n",
    "        return x_cat,x_cont,self.concat(raw_outputs),self.concat(outputs),torch.cat(masks,dim=1)\n",
    "\n",
    "class SequentialMultipleInput(SequentialRNN):\n",
    "    \"A workaround for multiple inputs in nn.Sequential\"\n",
    "    def forward(self,*input):\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabular_text_classifier(emb_szs:ListSizes, n_cont:int , n_class:int, layers:Collection[int], \n",
    "                                # text classifier params inputs\n",
    "                                arch:Callable, vocab_sz:int, bptt:int=70, max_len:int=20*70, config:dict=None, \n",
    "                                drop_mult:float=1., lin_ftrs:Collection[int]=None, ps_lin_ftrs:Collection[float]=None,pad_idx:int=1,\n",
    "                                # tabular params inputs\n",
    "                                ps:Collection[float]=None,emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, bn_final:bool=False\n",
    "                               ) -> nn.Module:\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    \n",
    "    meta = text.learner._model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas'].copy())\n",
    "    for k in config.keys(): \n",
    "        if k.endswith('_p'): config[k] *= drop_mult # drop_mult: multiply to different dropouts in AWD LSTM\n",
    "    if lin_ftrs is None: lin_ftrs = []\n",
    "    if ps_lin_ftrs is None:  ps_lin_ftrs = []\n",
    "    \n",
    "    rnn_lin_layers = [config[meta['hid_name']] * 3] + lin_ftrs + [n_class] # [1200, 50, 1]\n",
    "    ps_lin_ftrs = [config.pop('output_p')] + ps_lin_ftrs #[0.4 (from output_p) for layer1200, 0.1 for layer50]\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = MultiBatchMixEncoder(bptt, max_len, arch(vocab_sz, **config), pad_idx=pad_idx)\n",
    "    \n",
    "    tabtext_lin_model = PoolingLinearTabularTextClassifier(rnn_lin_layers, ps_lin_ftrs,\n",
    "                                                       # tabular params inputs\n",
    "                                                      emb_szs,n_cont,n_class,layers,ps,emb_drop,y_range,use_bn,bn_final)\n",
    "\n",
    "    # Problem: SequentialRNN is nn.Sequential, and nn.Sequential has its own forward which is accepting only one argument\n",
    "    # Workaround\n",
    "    final_model = SequentialMultipleInput(encoder, tabtext_lin_model)\n",
    "    return final_model if init is None else final_model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabtext_learner(data,\n",
    "                    arch:Callable,\n",
    "                    metrics=None,\n",
    "                    layers:Collection[int]=[400,200],                    \n",
    "                    # text classifier params inputs                   \n",
    "                    bptt:int=70, max_len:int=20*70, config:dict=None,                     \n",
    "                    drop_mult:float=1., lin_ftrs:Collection[int]=None, ps_lin_ftrs:Collection[float]=None,pad_idx:int=1,\n",
    "                    # tabular params inputs\n",
    "                    emb_szs:Dict[str,int]=None, ps:Collection[float]=None,emb_drop:float=0., \n",
    "                    y_range:OptRange=None, use_bn:bool=True, bn_final:bool=False,pretrained:bool=True, **learn_kwargs):\n",
    "    #tabular\n",
    "    emb_szs = data.get_emb_szs(ifnone(emb_szs, {}))\n",
    "    model = get_tabular_text_classifier(emb_szs,len(data.cont_names),data.c,layers,\n",
    "                                       arch,len(data.vocab.itos),bptt=bptt,max_len=max_len,config=config,\n",
    "                                        drop_mult=drop_mult, lin_ftrs=lin_ftrs,ps_lin_ftrs=ps_lin_ftrs,\n",
    "                                        pad_idx=pad_idx,ps=ps,emb_drop=emb_drop,y_range=y_range,\n",
    "                                       use_bn=use_bn,bn_final=bn_final)\n",
    "    #text\n",
    "    meta = text.learner._model_meta[arch]\n",
    "    learn = RNNLearner(data, model, metrics = metrics, split_func=meta['split_clas'], **learn_kwargs)\n",
    "    if pretrained:\n",
    "        if 'url' not in meta: \n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn.load_pretrained(*fnames, strict=False)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "encoder_name = 'bs60-awdlstm-enc-stage2'\n",
    "def get_tabtext_lr_find(data,params,seed=42):\n",
    "    reset_seed(seed)\n",
    "    learn_lf = tabtext_learner(data,AWD_LSTM,metrics=[root_mean_squared_error],**params).to_fp16()\n",
    "    learn_lf.load_encoder(encoder_name)\n",
    "    return learn_lf.to_fp32()\n",
    "\n",
    "def get_tabulartext_learner(data,params):\n",
    "    learn= tabtext_learner(data,AWD_LSTM,metrics=[root_mean_squared_error],\n",
    "                               callback_fns=[partial(SaveModelCallback, monitor='root_mean_squared_error',mode='min',every='improvement',name='best_nn')],\n",
    "                               **params)\n",
    "    learn.load_encoder(encoder_name)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'layers': [400,400,200], # neural network at model's head\n",
    "    'ps': [0.001,0.,0.], # dropout for NN at model's head\n",
    "    'bptt': 70,\n",
    "    'max_len': 20*70,\n",
    "    'drop_mult': 1., # multiply to different dropouts in AWD LSTM\n",
    "    'lin_ftrs': [300], # dropout for this linear layer at AWD_LSTM output\n",
    "    'ps_lin_ftrs': [0.],\n",
    "    'emb_drop': 0., # embeddings dropout\n",
    "    'y_range': [0,6], # restrict y range for regression problem\n",
    "    'use_bn': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_tabulartext_learner(data,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1,max_lr=1e-02,pct_start=0.3,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
